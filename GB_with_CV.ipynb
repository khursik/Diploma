{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_2</th>\n",
       "      <th>1_3</th>\n",
       "      <th>1_4</th>\n",
       "      <th>1_5</th>\n",
       "      <th>1_6</th>\n",
       "      <th>2_1</th>\n",
       "      <th>2_2</th>\n",
       "      <th>2_3</th>\n",
       "      <th>2_4</th>\n",
       "      <th>...</th>\n",
       "      <th>62_5</th>\n",
       "      <th>62_6</th>\n",
       "      <th>63_1</th>\n",
       "      <th>63_2</th>\n",
       "      <th>63_3</th>\n",
       "      <th>63_4</th>\n",
       "      <th>63_5</th>\n",
       "      <th>63_6</th>\n",
       "      <th>name</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.148821e-12</td>\n",
       "      <td>1.762882e-12</td>\n",
       "      <td>1.459278e-13</td>\n",
       "      <td>1.587917e-13</td>\n",
       "      <td>8.052632e-14</td>\n",
       "      <td>9.811591e-14</td>\n",
       "      <td>4.880873e-12</td>\n",
       "      <td>3.717614e-12</td>\n",
       "      <td>5.085536e-14</td>\n",
       "      <td>1.059260e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.276443e-12</td>\n",
       "      <td>8.376371e-13</td>\n",
       "      <td>2.611143e-12</td>\n",
       "      <td>4.619382e-12</td>\n",
       "      <td>9.115283e-13</td>\n",
       "      <td>4.653725e-13</td>\n",
       "      <td>6.211839e-13</td>\n",
       "      <td>8.285990e-13</td>\n",
       "      <td>chcon_s_100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.270260e-12</td>\n",
       "      <td>8.164477e-13</td>\n",
       "      <td>5.903729e-13</td>\n",
       "      <td>3.056763e-13</td>\n",
       "      <td>1.406329e-13</td>\n",
       "      <td>1.300234e-13</td>\n",
       "      <td>1.355080e-12</td>\n",
       "      <td>1.772045e-12</td>\n",
       "      <td>3.034272e-13</td>\n",
       "      <td>5.719425e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>8.724144e-13</td>\n",
       "      <td>1.631172e-12</td>\n",
       "      <td>3.973207e-12</td>\n",
       "      <td>3.763169e-12</td>\n",
       "      <td>1.845015e-12</td>\n",
       "      <td>1.511330e-12</td>\n",
       "      <td>1.079865e-12</td>\n",
       "      <td>2.844522e-12</td>\n",
       "      <td>chcon_s_100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.709517e-13</td>\n",
       "      <td>1.717117e-13</td>\n",
       "      <td>3.039963e-13</td>\n",
       "      <td>1.663584e-13</td>\n",
       "      <td>1.726942e-13</td>\n",
       "      <td>1.575523e-14</td>\n",
       "      <td>8.081481e-13</td>\n",
       "      <td>3.148841e-13</td>\n",
       "      <td>2.274227e-13</td>\n",
       "      <td>2.398548e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>4.848598e-13</td>\n",
       "      <td>2.998910e-12</td>\n",
       "      <td>7.980503e-13</td>\n",
       "      <td>1.972731e-12</td>\n",
       "      <td>1.151927e-12</td>\n",
       "      <td>1.502789e-12</td>\n",
       "      <td>1.407080e-12</td>\n",
       "      <td>4.519942e-12</td>\n",
       "      <td>chcon_s_100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.800220e-12</td>\n",
       "      <td>3.611335e-13</td>\n",
       "      <td>9.828645e-13</td>\n",
       "      <td>3.723583e-13</td>\n",
       "      <td>1.130286e-13</td>\n",
       "      <td>1.024523e-13</td>\n",
       "      <td>6.833368e-12</td>\n",
       "      <td>1.860960e-13</td>\n",
       "      <td>9.452324e-13</td>\n",
       "      <td>1.900433e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.179424e-12</td>\n",
       "      <td>1.033002e-12</td>\n",
       "      <td>2.197372e-12</td>\n",
       "      <td>7.087539e-13</td>\n",
       "      <td>8.981474e-13</td>\n",
       "      <td>9.161498e-13</td>\n",
       "      <td>6.247119e-13</td>\n",
       "      <td>1.532856e-12</td>\n",
       "      <td>chcon_s_100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.507999e-13</td>\n",
       "      <td>4.833313e-13</td>\n",
       "      <td>1.694255e-12</td>\n",
       "      <td>1.434799e-13</td>\n",
       "      <td>1.543624e-13</td>\n",
       "      <td>1.756470e-14</td>\n",
       "      <td>2.416072e-12</td>\n",
       "      <td>9.628125e-13</td>\n",
       "      <td>2.960569e-12</td>\n",
       "      <td>1.021592e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>4.516402e-13</td>\n",
       "      <td>2.892556e-13</td>\n",
       "      <td>4.063033e-12</td>\n",
       "      <td>1.206668e-12</td>\n",
       "      <td>1.582814e-12</td>\n",
       "      <td>6.090663e-13</td>\n",
       "      <td>1.444978e-12</td>\n",
       "      <td>2.585149e-12</td>\n",
       "      <td>chcon_s_100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 380 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1_1           1_2           1_3           1_4           1_5  \\\n",
       "0  2.148821e-12  1.762882e-12  1.459278e-13  1.587917e-13  8.052632e-14   \n",
       "1  1.270260e-12  8.164477e-13  5.903729e-13  3.056763e-13  1.406329e-13   \n",
       "2  7.709517e-13  1.717117e-13  3.039963e-13  1.663584e-13  1.726942e-13   \n",
       "3  2.800220e-12  3.611335e-13  9.828645e-13  3.723583e-13  1.130286e-13   \n",
       "4  9.507999e-13  4.833313e-13  1.694255e-12  1.434799e-13  1.543624e-13   \n",
       "\n",
       "            1_6           2_1           2_2           2_3           2_4  ...  \\\n",
       "0  9.811591e-14  4.880873e-12  3.717614e-12  5.085536e-14  1.059260e-13  ...   \n",
       "1  1.300234e-13  1.355080e-12  1.772045e-12  3.034272e-13  5.719425e-13  ...   \n",
       "2  1.575523e-14  8.081481e-13  3.148841e-13  2.274227e-13  2.398548e-13  ...   \n",
       "3  1.024523e-13  6.833368e-12  1.860960e-13  9.452324e-13  1.900433e-13  ...   \n",
       "4  1.756470e-14  2.416072e-12  9.628125e-13  2.960569e-12  1.021592e-13  ...   \n",
       "\n",
       "           62_5          62_6          63_1          63_2          63_3  \\\n",
       "0  1.276443e-12  8.376371e-13  2.611143e-12  4.619382e-12  9.115283e-13   \n",
       "1  8.724144e-13  1.631172e-12  3.973207e-12  3.763169e-12  1.845015e-12   \n",
       "2  4.848598e-13  2.998910e-12  7.980503e-13  1.972731e-12  1.151927e-12   \n",
       "3  1.179424e-12  1.033002e-12  2.197372e-12  7.087539e-13  8.981474e-13   \n",
       "4  4.516402e-13  2.892556e-13  4.063033e-12  1.206668e-12  1.582814e-12   \n",
       "\n",
       "           63_4          63_5          63_6         name  task  \n",
       "0  4.653725e-13  6.211839e-13  8.285990e-13  chcon_s_100     0  \n",
       "1  1.511330e-12  1.079865e-12  2.844522e-12  chcon_s_100     0  \n",
       "2  1.502789e-12  1.407080e-12  4.519942e-12  chcon_s_100     0  \n",
       "3  9.161498e-13  6.247119e-13  1.532856e-12  chcon_s_100     0  \n",
       "4  6.090663e-13  1.444978e-12  2.585149e-12  chcon_s_100     0  \n",
       "\n",
       "[5 rows x 380 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"EDA/data/with_avg_vals.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3709           10.75m\n",
      "         2           1.3635           10.71m\n",
      "         3           1.3578           10.64m\n",
      "         4           1.3513           10.58m\n",
      "         5           1.3438           10.48m\n",
      "         6           1.3375           10.43m\n",
      "         7           1.3320           10.40m\n",
      "         8           1.3259           10.33m\n",
      "         9           1.3211           10.30m\n",
      "        10           1.3158           10.24m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3698           10.62m\n",
      "         2           1.3623           10.54m\n",
      "         3           1.3563           10.57m\n",
      "         4           1.3494           10.51m\n",
      "         5           1.3428           10.45m\n",
      "         6           1.3358           10.39m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3687           10.53m\n",
      "         2           1.3607           10.52m\n",
      "         3           1.3537           10.50m\n",
      "         4           1.3469           10.47m\n",
      "         5           1.3400           10.41m\n",
      "         6           1.3335           10.36m\n",
      "         7           1.3287           10.32m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3702           10.61m\n",
      "         2           1.3629           10.57m\n",
      "         3           1.3561           10.54m\n",
      "         4           1.3493           10.53m\n",
      "         5           1.3433           10.47m\n",
      "         6           1.3368           10.44m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3701           10.74m\n",
      "         2           1.3633           10.66m\n",
      "         3           1.3553           10.57m\n",
      "         4           1.3496           10.52m\n",
      "         5           1.3422           10.43m\n",
      "         6           1.3356           10.35m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3743           10.68m\n",
      "         2           1.3707           10.65m\n",
      "         3           1.3674           10.61m\n",
      "         4           1.3637           10.53m\n",
      "         5           1.3601           10.45m\n",
      "         6           1.3564           10.39m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3736           10.43m\n",
      "         2           1.3705           10.47m\n",
      "         3           1.3670           10.43m\n",
      "         4           1.3643           10.42m\n",
      "         5           1.3607           10.37m\n",
      "         6           1.3569           10.29m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3735           10.65m\n",
      "         2           1.3693           10.62m\n",
      "         3           1.3652           10.55m\n",
      "         4           1.3617           10.49m\n",
      "         5           1.3588           10.47m\n",
      "         6           1.3544           10.39m\n",
      "         7           1.3509           10.33m\n",
      "         8           1.3476           10.27m\n",
      "         9           1.3441           10.22m\n",
      "        10           1.3405           10.16m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3737           10.73m\n",
      "         2           1.3697           10.58m\n",
      "         3           1.3666           10.64m\n",
      "         4           1.3626           10.60m\n",
      "         5           1.3593           10.59m\n",
      "         6           1.3563           10.57m\n",
      "         7           1.3528           10.51m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3734           10.55m\n",
      "         2           1.3694           10.64m\n",
      "         3           1.3655           10.53m\n",
      "         4           1.3622           10.54m\n",
      "         5           1.3593           10.51m\n",
      "         6           1.3561           10.46m\n",
      "         7           1.3528           10.38m\n",
      "         8           1.3492           10.33m\n",
      "         9           1.3464           10.29m\n",
      "        10           1.3427           10.23m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3761           10.68m\n",
      "         2           1.3742           10.74m\n",
      "         3           1.3722           10.70m\n",
      "         4           1.3705           10.67m\n",
      "         5           1.3689           10.60m\n",
      "         6           1.3670           10.53m\n",
      "         7           1.3652           10.48m\n",
      "         8           1.3637           10.42m\n",
      "         9           1.3619           10.35m\n",
      "        10           1.3602           10.29m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3761           10.64m\n",
      "         2           1.3740           10.70m\n",
      "         3           1.3721           10.68m\n",
      "         4           1.3702           10.58m\n",
      "         5           1.3684           10.53m\n",
      "         6           1.3666           10.46m\n",
      "         7           1.3648           10.42m\n",
      "         8           1.3630           10.38m\n",
      "         9           1.3615           10.33m\n",
      "        10           1.3599           10.28m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3758           10.63m\n",
      "         2           1.3735           10.57m\n",
      "         3           1.3714           10.57m\n",
      "         4           1.3693           10.57m\n",
      "         5           1.3675           10.51m\n",
      "         6           1.3658           10.43m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3758           10.70m\n",
      "         2           1.3737           10.68m\n",
      "         3           1.3720           10.65m\n",
      "         4           1.3704           10.62m\n",
      "         5           1.3687           10.59m\n",
      "         6           1.3669           10.54m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3759           10.75m\n",
      "         2           1.3738           10.65m\n",
      "         3           1.3719           10.60m\n",
      "         4           1.3699           10.53m\n",
      "         5           1.3680           10.47m\n",
      "         6           1.3663           10.41m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3741           13.40m\n",
      "         2           1.3705           13.36m\n",
      "         3           1.3672           13.39m\n",
      "         4           1.3640           13.36m\n",
      "         5           1.3617           13.33m\n",
      "         6           1.3587           13.25m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingClassifier(n_estimators=200,\n",
       "                                                  n_iter_no_change=5,\n",
       "                                                  verbose=1),\n",
       "             param_grid={'learning_rate': [0.2, 0.1, 0.05]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, :-2].values\n",
    "y = df.task\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=200, verbose=1, n_iter_no_change=5)\n",
    "clf = GridSearchCV(model, {'learning_rate': [0.2, 0.1, 0.05]}, return_train_score=True)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2946531429560279"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.476748</td>\n",
       "      <td>8.832794</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.2}</td>\n",
       "      <td>0.259277</td>\n",
       "      <td>0.286989</td>\n",
       "      <td>0.284641</td>\n",
       "      <td>0.295583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285542</td>\n",
       "      <td>0.014418</td>\n",
       "      <td>3</td>\n",
       "      <td>0.431290</td>\n",
       "      <td>0.384661</td>\n",
       "      <td>0.392882</td>\n",
       "      <td>0.374985</td>\n",
       "      <td>0.373811</td>\n",
       "      <td>0.391526</td>\n",
       "      <td>0.021060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.727913</td>\n",
       "      <td>9.890366</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1}</td>\n",
       "      <td>0.287459</td>\n",
       "      <td>0.301080</td>\n",
       "      <td>0.302020</td>\n",
       "      <td>0.289944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294653</td>\n",
       "      <td>0.005884</td>\n",
       "      <td>1</td>\n",
       "      <td>0.356002</td>\n",
       "      <td>0.359408</td>\n",
       "      <td>0.403101</td>\n",
       "      <td>0.358544</td>\n",
       "      <td>0.371932</td>\n",
       "      <td>0.369797</td>\n",
       "      <td>0.017542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.807456</td>\n",
       "      <td>14.096740</td>\n",
       "      <td>0.003730</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'learning_rate': 0.05}</td>\n",
       "      <td>0.280413</td>\n",
       "      <td>0.301080</td>\n",
       "      <td>0.295444</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289955</td>\n",
       "      <td>0.007361</td>\n",
       "      <td>2</td>\n",
       "      <td>0.374560</td>\n",
       "      <td>0.362227</td>\n",
       "      <td>0.346723</td>\n",
       "      <td>0.344451</td>\n",
       "      <td>0.329419</td>\n",
       "      <td>0.351476</td>\n",
       "      <td>0.015536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      24.476748      8.832794         0.003782        0.000778   \n",
       "1      27.727913      9.890366         0.003864        0.000363   \n",
       "2      29.807456     14.096740         0.003730        0.000617   \n",
       "\n",
       "  param_learning_rate                   params  split0_test_score  \\\n",
       "0                 0.2   {'learning_rate': 0.2}           0.259277   \n",
       "1                 0.1   {'learning_rate': 0.1}           0.287459   \n",
       "2                0.05  {'learning_rate': 0.05}           0.280413   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  ...  \\\n",
       "0           0.286989           0.284641           0.295583  ...   \n",
       "1           0.301080           0.302020           0.289944  ...   \n",
       "2           0.301080           0.295444           0.285714  ...   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.285542        0.014418                3            0.431290   \n",
       "1         0.294653        0.005884                1            0.356002   \n",
       "2         0.289955        0.007361                2            0.374560   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.384661            0.392882            0.374985   \n",
       "1            0.359408            0.403101            0.358544   \n",
       "2            0.362227            0.346723            0.344451   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.373811          0.391526         0.021060  \n",
       "1            0.371932          0.369797         0.017542  \n",
       "2            0.329419          0.351476         0.015536  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ÐŸÑ€Ð¾Ð²ÐµÐ´Ñ‘Ð¼ Ð¾Ñ‚Ð±Ð¾Ñ€ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    379.000000\n",
       "mean      -0.001099\n",
       "std        0.052680\n",
       "min       -0.028795\n",
       "25%       -0.011799\n",
       "50%       -0.003578\n",
       "75%        0.003062\n",
       "max        1.000000\n",
       "Name: task, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['name'], axis=1).corr()['task'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = PermutationImportance(clf, random_state=1).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0206\n",
       "                \n",
       "                    &plusmn; 0.0068\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                59_1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.60%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0129\n",
       "                \n",
       "                    &plusmn; 0.0033\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                37_6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.76%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0039\n",
       "                \n",
       "                    &plusmn; 0.0019\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                11_5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0036\n",
       "                \n",
       "                    &plusmn; 0.0028\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                1_1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.56%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0032\n",
       "                \n",
       "                    &plusmn; 0.0013\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                35_6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.58%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0032\n",
       "                \n",
       "                    &plusmn; 0.0046\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                37_5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.10%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0028\n",
       "                \n",
       "                    &plusmn; 0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                15_6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0026\n",
       "                \n",
       "                    &plusmn; 0.0013\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                30_5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.34%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0026\n",
       "                \n",
       "                    &plusmn; 0.0015\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                15_1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.58%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0024\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                42_1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0019\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                33_5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0017\n",
       "                \n",
       "                    &plusmn; 0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                63_6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.74%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0015\n",
       "                \n",
       "                    &plusmn; 0.0010\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                26_4\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0015\n",
       "                \n",
       "                    &plusmn; 0.0010\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                43_6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.83%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0015\n",
       "                \n",
       "                    &plusmn; 0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                63_3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.97%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "                    &plusmn; 0.0020\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                47_4\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.97%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "                    &plusmn; 0.0010\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                42_6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.38%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0011\n",
       "                \n",
       "                    &plusmn; 0.0021\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                43_1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.48%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0011\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                32_6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.51%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0011\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                59_3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 97.51%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 358 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(perm, feature_names = df.iloc[:, :-2].columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 1 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_new \u001b[38;5;241m=\u001b[39m \u001b[43mSelectKBest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:855\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_base.py:90\u001b[0m, in \u001b[0;36mSelectorMixin.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# note: we use _safe_tags instead of _get_tags because this is a\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# public Mixin.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m     84\u001b[0m     X,\n\u001b[1;32m     85\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     89\u001b[0m )\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_base.py:94\u001b[0m, in \u001b[0;36mSelectorMixin._transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124;03m\"\"\"Reduce X to the selected features.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m     96\u001b[0m         warn(\n\u001b[1;32m     97\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo features were selected: either the data is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m too noisy or the selection test too strict.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    100\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_base.py:53\u001b[0m, in \u001b[0;36mSelectorMixin.get_support\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_support\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    Get a mask, or integer index, of the features selected.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m        values are indices into the input feature vector.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_support_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mask \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indices \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(mask)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:622\u001b[0m, in \u001b[0;36mSelectKBest._get_support_mask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    618\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(scores\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m    620\u001b[0m \u001b[38;5;66;03m# Request a stable sort. Mergesort takes more memory (~40MB per\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;66;03m# megafeature on x86-64).\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m mask[np\u001b[38;5;241m.\u001b[39margsort(scores, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmergesort\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk :]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mask\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 1 were indexed"
     ]
    }
   ],
   "source": [
    "X_new = SelectKBest(clf.score, k=50).fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_model = SelectFromModel(clf, prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "when `importance_getter=='auto'`, the underlying estimator GridSearchCV should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_new \u001b[38;5;241m=\u001b[39m \u001b[43mselection_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_base.py:90\u001b[0m, in \u001b[0;36mSelectorMixin.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# note: we use _safe_tags instead of _get_tags because this is a\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# public Mixin.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m     84\u001b[0m     X,\n\u001b[1;32m     85\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     89\u001b[0m )\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_base.py:94\u001b[0m, in \u001b[0;36mSelectorMixin._transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124;03m\"\"\"Reduce X to the selected features.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m     96\u001b[0m         warn(\n\u001b[1;32m     97\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo features were selected: either the data is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m too noisy or the selection test too strict.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    100\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_base.py:53\u001b[0m, in \u001b[0;36mSelectorMixin.get_support\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_support\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    Get a mask, or integer index, of the features selected.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m        values are indices into the input feature vector.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_support_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mask \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indices \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(mask)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:211\u001b[0m, in \u001b[0;36mSelectFromModel._get_support_mask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither fit the model before transform or set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefit=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m while passing the fitted\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m estimator to the constructor.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m     )\n\u001b[0;32m--> 211\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43m_get_feature_importances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgetter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimportance_getter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnorm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m threshold \u001b[38;5;241m=\u001b[39m _calculate_threshold(estimator, scores, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_base.py:204\u001b[0m, in \u001b[0;36m_get_feature_importances\u001b[0;34m(estimator, getter, transform_func, norm_order)\u001b[0m\n\u001b[1;32m    202\u001b[0m         getter \u001b[38;5;241m=\u001b[39m attrgetter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_importances_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    205\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen `importance_getter==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`, the underlying \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`coef_` or `feature_importances_` attribute. Either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass a fitted estimator to feature selector or call fit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore calling transform.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m         )\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     getter \u001b[38;5;241m=\u001b[39m attrgetter(getter)\n",
      "\u001b[0;31mValueError\u001b[0m: when `importance_getter=='auto'`, the underlying estimator GridSearchCV should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform."
     ]
    }
   ],
   "source": [
    "X_new = smodel.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
